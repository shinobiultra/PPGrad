<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.5"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>PPGrad: include/NumericalGradientTests.hpp File Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">PPGrad
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.5 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('NumericalGradientTests_8hpp.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="summary">
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle"><div class="title">NumericalGradientTests.hpp File Reference</div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><code>#include &quot;<a class="el" href="TensorBase_8hpp_source.html">Tensor/TensorBase.hpp</a>&quot;</code><br />
<code>#include &lt;unsupported/Eigen/CXX11/Tensor&gt;</code><br />
<code>#include &lt;vector&gt;</code><br />
<code>#include &lt;memory&gt;</code><br />
</div>
<p><a href="NumericalGradientTests_8hpp_source.html">Go to the source code of this file.</a></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:a392c15f3ed33028100d87c46167d3b5c"><td class="memItemLeft" align="right" valign="top">std::vector&lt; Eigen::Tensor&lt; double, 2 &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="NumericalGradientTests_8hpp.html#a392c15f3ed33028100d87c46167d3b5c">estimateGradients</a> (std::vector&lt; Eigen::Tensor&lt; double, 2 &gt; &gt; &amp;inputTensors, std::function&lt; double(std::vector&lt; Eigen::Tensor&lt; double, 2 &gt; &gt;)&gt; L)</td></tr>
<tr class="memdesc:a392c15f3ed33028100d87c46167d3b5c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Numerical estimate gradients of L wrt all items in inputTensors.  <a href="NumericalGradientTests_8hpp.html#a392c15f3ed33028100d87c46167d3b5c">More...</a><br /></td></tr>
<tr class="separator:a392c15f3ed33028100d87c46167d3b5c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7d99520b043b3ff9988c06e90668b100"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="NumericalGradientTests_8hpp.html#a7d99520b043b3ff9988c06e90668b100">LSumMult</a> (std::vector&lt; Eigen::Tensor&lt; double, 2 &gt; &gt; inputTensors)</td></tr>
<tr class="memdesc:a7d99520b043b3ff9988c06e90668b100"><td class="mdescLeft">&#160;</td><td class="mdescRight">Function that interleaves addition &amp; multiplication of tensors, intended for testing gradients.  <a href="NumericalGradientTests_8hpp.html#a7d99520b043b3ff9988c06e90668b100">More...</a><br /></td></tr>
<tr class="separator:a7d99520b043b3ff9988c06e90668b100"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad74b1f7bf601dc11d89cbbe0a044299f"><td class="memItemLeft" align="right" valign="top">std::vector&lt; std::shared_ptr&lt; <a class="el" href="classPPGrad_1_1TensorBase.html">PPGrad::TensorBase</a>&lt; 2, double &gt; &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="NumericalGradientTests_8hpp.html#ad74b1f7bf601dc11d89cbbe0a044299f">LSumMult</a> (std::vector&lt; std::shared_ptr&lt; <a class="el" href="classPPGrad_1_1TensorBase.html">PPGrad::TensorBase</a>&lt; 2, double &gt; &gt; &gt; inputTensors, bool autoBackward=false)</td></tr>
<tr class="memdesc:ad74b1f7bf601dc11d89cbbe0a044299f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Function that interleaves addition &amp; multiplication of tensors, intended for testing gradients. Calls _bakcward() on each tensor manually.  <a href="NumericalGradientTests_8hpp.html#ad74b1f7bf601dc11d89cbbe0a044299f">More...</a><br /></td></tr>
<tr class="separator:ad74b1f7bf601dc11d89cbbe0a044299f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3924eaebbf64eac39b87de3acc387b6d"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="NumericalGradientTests_8hpp.html#a3924eaebbf64eac39b87de3acc387b6d">LSumMixed</a> (std::vector&lt; Eigen::Tensor&lt; double, 2 &gt; &gt; inputTensors)</td></tr>
<tr class="memdesc:a3924eaebbf64eac39b87de3acc387b6d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Function for thoroughly testing gradients.  <a href="NumericalGradientTests_8hpp.html#a3924eaebbf64eac39b87de3acc387b6d">More...</a><br /></td></tr>
<tr class="separator:a3924eaebbf64eac39b87de3acc387b6d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa10e3fa671d82bc5ad783c843063c253"><td class="memItemLeft" align="right" valign="top">std::vector&lt; std::shared_ptr&lt; <a class="el" href="classPPGrad_1_1TensorBase.html">PPGrad::TensorBase</a>&lt; 2, double &gt; &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="NumericalGradientTests_8hpp.html#aa10e3fa671d82bc5ad783c843063c253">LSumMixed</a> (std::vector&lt; std::shared_ptr&lt; <a class="el" href="classPPGrad_1_1TensorBase.html">PPGrad::TensorBase</a>&lt; 2, double &gt; &gt; &gt; inputTensors, bool autoBackward=false)</td></tr>
<tr class="memdesc:aa10e3fa671d82bc5ad783c843063c253"><td class="mdescLeft">&#160;</td><td class="mdescRight">Function for thoroughly testing gradients.  <a href="NumericalGradientTests_8hpp.html#aa10e3fa671d82bc5ad783c843063c253">More...</a><br /></td></tr>
<tr class="separator:aa10e3fa671d82bc5ad783c843063c253"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9d1367ef60c3da3e5a3003d384668250"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="NumericalGradientTests_8hpp.html#a9d1367ef60c3da3e5a3003d384668250">LMultSumShapes</a> (std::vector&lt; Eigen::Tensor&lt; double, 2 &gt; &gt; inputTensors)</td></tr>
<tr class="memdesc:a9d1367ef60c3da3e5a3003d384668250"><td class="mdescLeft">&#160;</td><td class="mdescRight">Multiply Tensors (T[i] * T[i+1]) with some scalar addition sparkled in and sum the result.  <a href="NumericalGradientTests_8hpp.html#a9d1367ef60c3da3e5a3003d384668250">More...</a><br /></td></tr>
<tr class="separator:a9d1367ef60c3da3e5a3003d384668250"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8a47d413ee883b957cd491db6fd51252"><td class="memItemLeft" align="right" valign="top">std::vector&lt; std::shared_ptr&lt; <a class="el" href="classPPGrad_1_1TensorBase.html">PPGrad::TensorBase</a>&lt; 2, double &gt; &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="NumericalGradientTests_8hpp.html#a8a47d413ee883b957cd491db6fd51252">LMultSumShapes</a> (std::vector&lt; std::shared_ptr&lt; <a class="el" href="classPPGrad_1_1TensorBase.html">PPGrad::TensorBase</a>&lt; 2, double &gt; &gt; &gt; inputTensors, bool autoBackward=false)</td></tr>
<tr class="memdesc:a8a47d413ee883b957cd491db6fd51252"><td class="mdescLeft">&#160;</td><td class="mdescRight">Multiply Tensors (T[i] * T[i+1]) with some scalar addition sparkled in and sum the result.  <a href="NumericalGradientTests_8hpp.html#a8a47d413ee883b957cd491db6fd51252">More...</a><br /></td></tr>
<tr class="separator:a8a47d413ee883b957cd491db6fd51252"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a591dafe81cc6215bf6d34b317021b74f"><td class="memItemLeft" align="right" valign="top"><a id="a591dafe81cc6215bf6d34b317021b74f" name="a591dafe81cc6215bf6d34b317021b74f"></a>
double&#160;</td><td class="memItemRight" valign="bottom"><b>LSumReLU</b> (std::vector&lt; Eigen::Tensor&lt; double, 2 &gt; &gt; inputTensors)</td></tr>
<tr class="separator:a591dafe81cc6215bf6d34b317021b74f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abe0fefbe2718fe6d721ab7291b0af0c9"><td class="memItemLeft" align="right" valign="top"><a id="abe0fefbe2718fe6d721ab7291b0af0c9" name="abe0fefbe2718fe6d721ab7291b0af0c9"></a>
std::vector&lt; std::shared_ptr&lt; <a class="el" href="classPPGrad_1_1TensorBase.html">PPGrad::TensorBase</a>&lt; 2, double &gt; &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>LSumReLU</b> (std::vector&lt; std::shared_ptr&lt; <a class="el" href="classPPGrad_1_1TensorBase.html">PPGrad::TensorBase</a>&lt; 2, double &gt; &gt; &gt; inputTensors)</td></tr>
<tr class="separator:abe0fefbe2718fe6d721ab7291b0af0c9"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<h2 class="groupheader">Function Documentation</h2>
<a id="a392c15f3ed33028100d87c46167d3b5c" name="a392c15f3ed33028100d87c46167d3b5c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a392c15f3ed33028100d87c46167d3b5c">&#9670;&#160;</a></span>estimateGradients()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt; Eigen::Tensor&lt; double, 2 &gt; &gt; estimateGradients </td>
          <td>(</td>
          <td class="paramtype">std::vector&lt; Eigen::Tensor&lt; double, 2 &gt; &gt; &amp;&#160;</td>
          <td class="paramname"><em>inputTensors</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::function&lt; double(std::vector&lt; Eigen::Tensor&lt; double, 2 &gt; &gt;)&gt;&#160;</td>
          <td class="paramname"><em>L</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Numerical estimate gradients of L wrt all items in inputTensors. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">inputTensors</td><td>Inputs of L. </td></tr>
    <tr><td class="paramname">L</td><td>Scalar function of inputTensors to differentiate. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>List of gradients of L wrt each item in inputTensors (i.e., same size as inputTensors with each item being the same size as the corresponding item in inputTensors </dd></dl>

</div>
</div>
<a id="a9d1367ef60c3da3e5a3003d384668250" name="a9d1367ef60c3da3e5a3003d384668250"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9d1367ef60c3da3e5a3003d384668250">&#9670;&#160;</a></span>LMultSumShapes() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double LMultSumShapes </td>
          <td>(</td>
          <td class="paramtype">std::vector&lt; Eigen::Tensor&lt; double, 2 &gt; &gt;&#160;</td>
          <td class="paramname"><em>inputTensors</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Multiply Tensors (T[i] * T[i+1]) with some scalar addition sparkled in and sum the result. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">inputTensors</td><td>Tensors to multiply. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Sum of the final tensor. </dd></dl>

</div>
</div>
<a id="a8a47d413ee883b957cd491db6fd51252" name="a8a47d413ee883b957cd491db6fd51252"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8a47d413ee883b957cd491db6fd51252">&#9670;&#160;</a></span>LMultSumShapes() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt; std::shared_ptr&lt; <a class="el" href="classPPGrad_1_1TensorBase.html">PPGrad::TensorBase</a>&lt; 2, double &gt; &gt; &gt; LMultSumShapes </td>
          <td>(</td>
          <td class="paramtype">std::vector&lt; std::shared_ptr&lt; <a class="el" href="classPPGrad_1_1TensorBase.html">PPGrad::TensorBase</a>&lt; 2, double &gt; &gt; &gt;&#160;</td>
          <td class="paramname"><em>inputTensors</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>autoBackward</em> = <code>false</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Multiply Tensors (T[i] * T[i+1]) with some scalar addition sparkled in and sum the result. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">inputTensors</td><td>Tensors to multiply. </td></tr>
    <tr><td class="paramname">autoBackward</td><td>Whether or not to call _backward() on each tensor automatically. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Vector of intermediate tensors. </dd></dl>

</div>
</div>
<a id="a3924eaebbf64eac39b87de3acc387b6d" name="a3924eaebbf64eac39b87de3acc387b6d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3924eaebbf64eac39b87de3acc387b6d">&#9670;&#160;</a></span>LSumMixed() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double LSumMixed </td>
          <td>(</td>
          <td class="paramtype">std::vector&lt; Eigen::Tensor&lt; double, 2 &gt; &gt;&#160;</td>
          <td class="paramname"><em>inputTensors</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Function for thoroughly testing gradients. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">inputTensors</td><td>Tensors to add, multiply and scalar multiply/divide. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Sum of the final tensor. </dd></dl>

</div>
</div>
<a id="aa10e3fa671d82bc5ad783c843063c253" name="aa10e3fa671d82bc5ad783c843063c253"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa10e3fa671d82bc5ad783c843063c253">&#9670;&#160;</a></span>LSumMixed() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt; std::shared_ptr&lt; <a class="el" href="classPPGrad_1_1TensorBase.html">PPGrad::TensorBase</a>&lt; 2, double &gt; &gt; &gt; LSumMixed </td>
          <td>(</td>
          <td class="paramtype">std::vector&lt; std::shared_ptr&lt; <a class="el" href="classPPGrad_1_1TensorBase.html">PPGrad::TensorBase</a>&lt; 2, double &gt; &gt; &gt;&#160;</td>
          <td class="paramname"><em>inputTensors</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>autoBackward</em> = <code>false</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Function for thoroughly testing gradients. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">inputTensors</td><td>Tensors to add, multiply and scalar multiply/divide. </td></tr>
    <tr><td class="paramname">autoBackward</td><td>Whether or not to call _backward() on each tensor automatically. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Vector of intermediate tensors. </dd></dl>

</div>
</div>
<a id="a7d99520b043b3ff9988c06e90668b100" name="a7d99520b043b3ff9988c06e90668b100"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7d99520b043b3ff9988c06e90668b100">&#9670;&#160;</a></span>LSumMult() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double LSumMult </td>
          <td>(</td>
          <td class="paramtype">std::vector&lt; Eigen::Tensor&lt; double, 2 &gt; &gt;&#160;</td>
          <td class="paramname"><em>inputTensors</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Function that interleaves addition &amp; multiplication of tensors, intended for testing gradients. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">inputTensors</td><td>Tensors to add and multiply. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Sum of the final tensor. </dd></dl>

</div>
</div>
<a id="ad74b1f7bf601dc11d89cbbe0a044299f" name="ad74b1f7bf601dc11d89cbbe0a044299f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad74b1f7bf601dc11d89cbbe0a044299f">&#9670;&#160;</a></span>LSumMult() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt; std::shared_ptr&lt; <a class="el" href="classPPGrad_1_1TensorBase.html">PPGrad::TensorBase</a>&lt; 2, double &gt; &gt; &gt; LSumMult </td>
          <td>(</td>
          <td class="paramtype">std::vector&lt; std::shared_ptr&lt; <a class="el" href="classPPGrad_1_1TensorBase.html">PPGrad::TensorBase</a>&lt; 2, double &gt; &gt; &gt;&#160;</td>
          <td class="paramname"><em>inputTensors</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>autoBackward</em> = <code>false</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Function that interleaves addition &amp; multiplication of tensors, intended for testing gradients. Calls _bakcward() on each tensor manually. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">inputTensors</td><td>Tensors to add and multiply. </td></tr>
    <tr><td class="paramname">autoBackward</td><td>Whether or not to call _backward() on each tensor automatically. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Vector of intermediate tensors. </dd></dl>

</div>
</div>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="dir_d44c64559bbebec7f509842c48db8b23.html">include</a></li><li class="navelem"><a class="el" href="NumericalGradientTests_8hpp.html">NumericalGradientTests.hpp</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.5 </li>
  </ul>
</div>
</body>
</html>
